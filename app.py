import streamlit as st
from openai import OpenAI
from PIL import Image
import requests
import uuid
import datetime
import os
import json
import boto3
from contenu_promptfight import Theorie_1, Enonce_1, Theorie_2, Enonce_2, Theorie_3, Enonce_3
from dotenv import load_dotenv

load_dotenv()

st.set_page_config(
    page_title="Atelier Prompting",
    layout="wide"      # üëà cl√© pour √©largir la fen√™tre
)

# Configuration des cl√©s API
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
MISTRAL_API_KEY = os.getenv("MISTRAL_API_KEY")
S3_PATH = os.getenv("S3_PATH")
AWS_ACCESS_KEY_ID = os.getenv("AWS_ACCESS_KEY_ID")
AWS_SECRET_ACCESS_KEY = os.getenv("AWS_SECRET_ACCESS_KEY")
AWS_REGION = os.getenv("AWS_REGION")
BUCKET_NAME = os.getenv("BUCKET_NAME")

client = OpenAI(api_key=OPENAI_API_KEY)

# Chargement logo et sidebar
logo = Image.open("assets/logo_disc.png")
with st.sidebar:
    col1, col2, col3 = st.columns([1, 6, 1])
    with col2:
        st.image(logo, width=300)
st.sidebar.markdown("---")

# Saisie pseudo et mod√®le
pseudo = st.sidebar.text_input("Renseignez votre pseudo")
st.sidebar.markdown("---")

# R√©glages des param√®tres
modele = st.sidebar.selectbox("Choix du mod√®le LLM", ["Mistral", "OpenAI"])
temperature = st.sidebar.slider("Temp√©rature", 0.0, 1.0, 0.7, step=0.1, help="Contr√¥le la cr√©ativit√© : plus elle est haute, plus les r√©ponses sont vari√©es.")
max_tokens = st.sidebar.slider("Max tokens", 10, 1024, 600, step=10, help="D√©finit la longueur maximale de la r√©ponse g√©n√©r√©e.")
top_p = st.sidebar.slider("Top-p", 0.0, 1.0, 1.0, step=0.1, help="Limite la diversit√© : plus c'est bas, plus les r√©ponses sont concentr√©es sur les options les plus probables.")

# Session unique pour diff√©rencier les logs
if "session_id" not in st.session_state:
    st.session_state.session_id = str(uuid.uuid4())

# Fonction d'appel LLM
def call_llm(prompt, model):
    if model == "OpenAI":
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            temperature=temperature,
            max_tokens=max_tokens,
            top_p=top_p
        )
        return response.choices[0].message.content.strip()

    elif model == "Mistral":
        headers = {
            "Authorization": f"Bearer {MISTRAL_API_KEY}",
            "Content-Type": "application/json",
        }
        data = {
            "model": "mistral-medium-latest",
            "messages": [{"role": "user", "content": prompt}],
            "temperature": temperature,
            "max_tokens": max_tokens,
            "top_p": top_p
        }
        r = requests.post("https://api.mistral.ai/v1/chat/completions", headers=headers, json=data)
        try:
            result = r.json()
            if "choices" in result:
                return result["choices"][0]["message"]["content"].strip()
            else:
                st.error(f"Erreur API Mistral : {result}")
                return "Erreur lors de l'appel √† l'API Mistral (voir d√©tails ci-dessus)"
        except Exception as e:
            st.error(f"R√©ponse invalide de l'API Mistral : {r.text}")
            return f"Exception: {e}"

def log_interaction(pseudo, exercice, prompt, response, model):
    timestamp = datetime.datetime.utcnow().isoformat().replace(":", "-")
    safe_exercice = exercice.replace(" ", "_")
    filename = f"log_{st.session_state.session_id}_{safe_exercice}_{timestamp}.json"

    log_data = {
        "timestamp": timestamp,
        "jour": datetime.datetime.now().strftime("%d/%m/%Y"),
        "session_id": st.session_state.session_id,
        "pseudo": pseudo,
        "exercice": exercice,
        "modele": model,
        "temperature": temperature,
        "max_tokens": max_tokens,
        "top_p": top_p,
        "prompt": prompt,
        "reponse": response
    }

    with open(filename, "w") as f:
        json.dump(log_data, f)

    s3 = boto3.client(
        "s3",
        aws_access_key_id=AWS_ACCESS_KEY_ID,
        aws_secret_access_key=AWS_SECRET_ACCESS_KEY,
        region_name=AWS_REGION
    )

    s3.upload_file(Filename=filename, Bucket=BUCKET_NAME, Key=filename)
    os.remove(filename)

# Cr√©ation des onglets d'exercice
tab1, tab2, tab3 = st.tabs(["Partie 1", "Partie 2", "Partie 3"])

#############################################################################
#############################      Partie 1     #############################
#############################################################################

with tab1:
    st.subheader(f"Partie 1 ‚Äì Les bases du prompting")

    st.markdown("""üéØ Objectif p√©dagogique  
    Comprendre ce qui fait un bon prompt : clart√©, contextualisation, sp√©cificit√©.""")
    
    prompt_key = "prompt_1"
    response_key = "response_1"
    reset_key = "reset_1"

    # Initialisation
    if prompt_key not in st.session_state:
        st.session_state[prompt_key] = ""
    if response_key not in st.session_state:
        st.session_state[response_key] = ""
    if reset_key not in st.session_state:
        st.session_state[reset_key] = False

    # Si reset demand√©
    if st.session_state[reset_key]:
        st.session_state[prompt_key] = ""
        st.session_state[response_key] = ""
        st.session_state[reset_key] = False
        st.rerun()

    # Contenu texte
    with st.expander("üìö Quelques rappels th√©oriques", expanded=False):
        st.markdown(Theorie_1, unsafe_allow_html=True)

    with st.container():
        st.markdown(Enonce_1, unsafe_allow_html=True)

    # Zone de saisie
    prompt = st.text_area("Pose ta question √† l'IA", value=st.session_state[prompt_key], key=prompt_key)

    col1, col2 = st.columns([1, 1])
    with col1:
        if st.button("Envoyer", key="btn_send_1"):
            if not pseudo:
                st.warning("Merci de renseigner un pseudo dans la barre lat√©rale.")
            elif not prompt.strip():
                st.warning("Merci d'√©crire une question.")
            else:
                with st.spinner("L'IA r√©fl√©chit..."):
                    reponse = call_llm(prompt, modele)
                    st.session_state[response_key] = reponse
                    log_interaction(pseudo, "Exercice 1", prompt, reponse, modele)

    with col2:
        if st.button("R√©initialiser", key="btn_reset_1"):
            st.session_state[reset_key] = True
            st.rerun()

    # Affichage r√©ponse
    if st.session_state[response_key]:
        st.markdown("### R√©ponse de l'IA")
        st.markdown(
            f'<div style="background-color:#e6ffe6;padding:10px;border-radius:5px;">{st.session_state[response_key]}</div>',
            unsafe_allow_html=True
        )

#############################################################################
#############################      Partie 2     #############################
#############################################################################

with tab2:
    st.subheader(f"Partie 2 ‚Äì Les formats de sortie")

    st.markdown("""üéØ Objectif p√©dagogique  
    Apprendre √† structurer ses demandes pour obtenir des formats de r√©ponse adapt√©s aux besoins professionnels.""")
    
    prompt_key = "prompt_2"
    response_key = "response_2"
    reset_key = "reset_2"

    # Initialisation
    if prompt_key not in st.session_state:
        st.session_state[prompt_key] = ""
    if response_key not in st.session_state:
        st.session_state[response_key] = ""
    if reset_key not in st.session_state:
        st.session_state[reset_key] = False

    # Si reset demand√©
    if st.session_state[reset_key]:
        st.session_state[prompt_key] = ""
        st.session_state[response_key] = ""
        st.session_state[reset_key] = False
        st.rerun()

    # Contenu texte
    with st.expander("üìö Quelques rappels th√©oriques", expanded=False):
        st.markdown(Theorie_2, unsafe_allow_html=True)

    with st.container():
        st.markdown(Enonce_2, unsafe_allow_html=True)

    # Aide rapide avec exemples de formats
    with st.expander("üí° Exemples de prompts avec formats", expanded=False):
        st.markdown("""
        **Format Email :**  
        *"Pr√©sente le lancement de ZenFlow sous forme d'email interne avec objet, contexte, d√©tails du produit et prochaines √©tapes pour l'√©quipe"*
        
        **Format Post LinkedIn :**  
        *"R√©dige un post LinkedIn pour annoncer ZenFlow avec une accroche engageante, 3 b√©n√©fices cl√©s, un appel √† l'action et des hashtags pertinents"*
        
        **Format Tableau :**  
        *"Cr√©e une fiche produit pour ZenFlow sous forme de tableau avec colonnes : Fonctionnalit√© | B√©n√©fice | Public cible"*
        """)

    # Zone de saisie
    prompt = st.text_area("Testez diff√©rents formats de sortie", value=st.session_state[prompt_key], key=prompt_key, height=100)

    col1, col2 = st.columns([1, 1])
    with col1:
        if st.button("Envoyer", key="btn_send_2"):
            if not pseudo:
                st.warning("Merci de renseigner un pseudo dans la barre lat√©rale.")
            elif not prompt.strip():
                st.warning("Merci d'√©crire une question.")
            else:
                with st.spinner("L'IA r√©fl√©chit..."):
                    reponse = call_llm(prompt, modele)
                    st.session_state[response_key] = reponse
                    log_interaction(pseudo, "Exercice 2", prompt, reponse, modele)

    with col2:
        if st.button("R√©initialiser", key="btn_reset_2"):
            st.session_state[reset_key] = True
            st.rerun()

    # Affichage r√©ponse
    if st.session_state[response_key]:
        st.markdown("### R√©ponse de l'IA")
        st.markdown(
            f'<div style="background-color:#e6f3ff;padding:10px;border-radius:5px;">{st.session_state[response_key]}</div>',
            unsafe_allow_html=True
        )

#############################################################################
#############################      Partie 3     #############################
#############################################################################

with tab3:
    st.subheader(f"Partie 3 ‚Äì Le Few-Shot Prompting")

    st.markdown("""üéØ Objectif p√©dagogique  
    Ma√Ætriser l'art de donner des exemples pour obtenir des r√©ponses coh√©rentes et dans le format souhait√©.""")
    
    prompt_key = "prompt_3"
    response_key = "response_3"
    reset_key = "reset_3"

    # Initialisation
    if prompt_key not in st.session_state:
        st.session_state[prompt_key] = ""
    if response_key not in st.session_state:
        st.session_state[response_key] = ""
    if reset_key not in st.session_state:
        st.session_state[reset_key] = False

    # Si reset demand√©
    if st.session_state[reset_key]:
        st.session_state[prompt_key] = ""
        st.session_state[response_key] = ""
        st.session_state[reset_key] = False
        st.rerun()

    # Contenu texte
    with st.expander("üìö Quelques rappels th√©oriques", expanded=False):
        st.markdown(Theorie_3, unsafe_allow_html=True)

    with st.container():
        st.markdown(Enonce_3, unsafe_allow_html=True)

    # Aide rapide avec template Few-Shot
    with st.expander("üí° Template Few-Shot √† utiliser", expanded=False):
        st.markdown("""
        **Structure recommand√©e :**
        ```
        √âcris un post dans le style d√©contract√© de TechFlow (startup tech avec humour et r√©f√©rences pop culture).

        Exemples :

        Sujet : Lancement nouvelle feature
        Post : "Plot twist ! üé¨ Notre nouvelle fonction 'AutoMagic' d√©barque demain et elle va r√©volutionner votre workflow comme Thanos a r√©volutionn√© l'univers Marvel (mais en mieux, promis) ‚ú® #TechLife #Innovation"

        Sujet : Bug r√©solu  
        Post : "Bug de ce matin = officiellement √©limin√© ! üêõüí• Notre √©quipe de ninjas-d√©veloppeurs a frapp√© plus vite que l'√©clair ‚ö° Merci pour votre patience, vous √™tes les meilleurs ! ‚ù§Ô∏è #TeamWork #FixItFast"

        Maintenant, √©cris pour le sujet : [VOTRE SUJET]
        ```
        """)

    # Suggestions de sujets √† tester
    st.markdown("**üí° Sujets sugg√©r√©s √† tester :**")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("üìù Recrutement stagiaire", key="sujet1"):
            st.session_state[prompt_key] = """√âcris un post dans le style d√©contract√© de TechFlow (startup tech avec humour et r√©f√©rences pop culture).

Exemples :

Sujet : Lancement nouvelle feature
Post : "Plot twist ! üé¨ Notre nouvelle fonction 'AutoMagic' d√©barque demain et elle va r√©volutionner votre workflow comme Thanos a r√©volutionn√© l'univers Marvel (mais en mieux, promis) ‚ú® #TechLife #Innovation"

Sujet : Bug r√©solu  
Post : "Bug de ce matin = officiellement √©limin√© ! üêõüí• Notre √©quipe de ninjas-d√©veloppeurs a frapp√© plus vite que l'√©clair ‚ö° Merci pour votre patience, vous √™tes les meilleurs ! ‚ù§Ô∏è #TeamWork #FixItFast"

Maintenant, √©cris pour le sujet : Recrutement d'un stagiaire d√©veloppeur"""

    with col2:
        if st.button("üîß Maintenance serveur", key="sujet2"):
            st.session_state[prompt_key] = """√âcris un post dans le style d√©contract√© de TechFlow (startup tech avec humour et r√©f√©rences pop culture).

Exemples :

Sujet : Lancement nouvelle feature
Post : "Plot twist ! üé¨ Notre nouvelle fonction 'AutoMagic' d√©barque demain et elle va r√©volutionner votre workflow comme Thanos a r√©volutionn√© l'univers Marvel (mais en mieux, promis) ‚ú® #TechLife #Innovation"

Sujet : Bug r√©solu  
Post : "Bug de ce matin = officiellement √©limin√© ! üêõüí• Notre √©quipe de ninjas-d√©veloppeurs a frapp√© plus vite que l'√©clair ‚ö° Merci pour votre patience, vous √™tes les meilleurs ! ‚ù§Ô∏è #TeamWork #FixItFast"

Maintenant, √©cris pour le sujet : Maintenance serveur pr√©vue ce weekend"""

    with col3:
        if st.button("ü§ù Nouveau partenariat", key="sujet3"):
            st.session_state[prompt_key] = """√âcris un post dans le style d√©contract√© de TechFlow (startup tech avec humeur et r√©f√©rences pop culture).

Exemples :

Sujet : Lancement nouvelle feature
Post : "Plot twist ! üé¨ Notre nouvelle fonction 'AutoMagic' d√©barque demain et elle va r√©volutionner votre workflow comme Thanos a r√©volutionn√© l'univers Marvel (mais en mieux, promis) ‚ú® #TechLife #Innovation"

Sujet : Bug r√©solu  
Post : "Bug de ce matin = officiellement √©limin√© ! üêõüí• Notre √©quipe de ninjas-d√©veloppeurs a frapp√© plus vite que l'√©clair ‚ö° Merci pour votre patience, vous √™tes les meilleurs ! ‚ù§Ô∏è #TeamWork #FixItFast"

Maintenant, √©cris pour le sujet : Partenariat avec une startup de design"""

    # Zone de saisie
    prompt = st.text_area("Testez vos prompts Few-Shot", value=st.session_state[prompt_key], key=prompt_key, height=150)

    col1, col2 = st.columns([1, 1])
    with col1:
        if st.button("Envoyer", key="btn_send_3"):
            if not pseudo:
                st.warning("Merci de renseigner un pseudo dans la barre lat√©rale.")
            elif not prompt.strip():
                st.warning("Merci d'√©crire une question.")
            else:
                with st.spinner("L'IA r√©fl√©chit..."):
                    reponse = call_llm(prompt, modele)
                    st.session_state[response_key] = reponse
                    log_interaction(pseudo, "Exercice 3", prompt, reponse, modele)

    with col2:
        if st.button("R√©initialiser", key="btn_reset_3"):
            st.session_state[reset_key] = True
            st.rerun()

    # Affichage r√©ponse
    if st.session_state[response_key]:
        st.markdown("### R√©ponse de l'IA")
        st.markdown(
            f'<div style="background-color:#fff3e6;padding:10px;border-radius:5px;">{st.session_state[response_key]}</div>',
            unsafe_allow_html=True
        )


# Un op√©rateur 31 ans travaille sur machine de cryobroyage de plantes dans un laboratoire pharmaceutique. Il se trouve face √† un dysfonctionnement de la machine. La vis sans fin de la cuve de pr√©cong√©lation est bloqu√©e par un corps √©tranger dans le conduit d'√©vacuation. L'op√©rateur proc√®de alors √† l'ouverture des couvercles de la cuve ce qui provoqua l'arr√™t du syst√®me d'entra√Ænement et l'arr√™t de l'injection d'azote liquide. Quelques heures plus tard, son corps a √©t√© d√©couvert inanim√© dans la cuve, les jambes et le bassin ainsi que les mains et les avant-bras gel√©s. Il para√Æt vraisemblable que l‚Äôop√©rateur a subi un choc thermique important et suffoqu√© en respirant un air glac√© nettement inf√©rieur √† z√©ro degr√© et o√π la proportion d'oxyg√®ne issu de l'air ambiant √©tait incertaine.

# La victime, un chercheur int√©rimaire de 40 ans, effectuait une mission d'animalier dans une soci√©t√© pharmaceutique et a √©t√© victime d'une d√©tresse respiratoire aigu√´ et d'un arr√™t cardiaque. Elle est d√©c√©d√©e √† l'h√¥pital 13 jours plus tard sans avoir repris connaissance.

# Un agent de conditionnement int√©rimaire de 52 ans travaille dans un laboratoire pharmaceutique. Il s'est rendu aux toilettes car il ne se sentait pas bien. Ne le voyant pas revenir, un coll√®gue est all√© le chercher. L'int√©rimaire avait perdu connaissance. Il avait d√©j√† fait un malaise le matin en arrivant au travail. Il est mort en fin de matin√©e.